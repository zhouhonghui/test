<!DOCTYPE html>
<html>
<head>
  <script src="js/face-api.min.js"></script>
  <script src="js/faceDetectionControls.js"></script>
  <link rel="stylesheet" href="styles.css">
  <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
</head>
<body>
    <div style="position: relative" class="margin">
      <video onloadedmetadata="onPlay(this)" id="inputVideo" autoplay muted playsinline></video>
      <canvas id="overlay"></canvas>
      <canvas width="640" height="480" id="canvas"></canvas>
    </div>

  <script>
    let forwardTimes = []

    function updateTimeStats(timeInMs) {
      forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30)
      const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length
      $('#time').val(`${Math.round(avgTimeInMs)} ms`)
      $('#fps').val(`${faceapi.utils.round(1000 / avgTimeInMs)}`)
    }

    async function onPlay() {
      const videoEl = $('#inputVideo').get(0)
      
      if(videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
        return setTimeout(() => onPlay())


      const options = getFaceDetectorOptions()

      const ts = Date.now()

      const result = await faceapi.detectSingleFace(videoEl, options)

      updateTimeStats(Date.now() - ts)

      if (result) {
        const canvas = $('#overlay').get(0)
        const dims = faceapi.matchDimensions(canvas, videoEl, true)
        faceapi.draw.drawDetections(canvas, faceapi.resizeResults(result, dims))
        const resizedResult = faceapi.resizeResults(result, dims)
        console.log("人脸识别成功",result)
        takePhoto()
      }

      setTimeout(() => onPlay())
    }

    // 拍照
    function takePhoto() {
        //获得Canvas对象
        let video = document.getElementById('inputVideo');
        let canvas = document.getElementById('canvas');
        let ctx = canvas.getContext('2d');
        ctx.drawImage(video, 0, 0, 640, 480);
        let img = document.getElementById('canvas').toDataURL();
        console.log('img-----', img);
        closeMedia()
    }

    // 关闭摄像头
    function closeMedia() {
        let stream = document.getElementById('inputVideo').srcObject;
        let tracks = stream.getTracks();
        tracks.forEach(function(track) {
          track.stop();
        });
        document.getElementById('inputVideo').srcObject = null;
    }

    async function run() {
      // load face detection model
      await changeFaceDetector(TINY_FACE_DETECTOR)
      changeInputSize(128)

      // try to access users webcam and stream the images
      // to the video element
      const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
      const videoEl = $('#inputVideo').get(0)
      videoEl.srcObject = stream
    }

    function updateResults() {}

    $(document).ready(function() {
      initFaceDetectionControls()
      run()
    })
  </script>
</body>
</html>